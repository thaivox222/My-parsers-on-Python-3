{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Пример парсера Кинопоиска. Автор (девушка, кстати) парсит выдачу с оценками фильмов на своем аккаунте\n",
    ", а у меня ни аккаунта,ни тем более оценок там - нет.\n",
    "Поэтому, только для разбора подхода парсинга'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Часть 1 - Загрузка данных'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# вводные\n",
    "s = requests.Session() # использует сессию, как и Мурренган\n",
    "s.headers.update({\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:45.0) Gecko/20100101 Firefox/45.0'\n",
    "    })\n",
    "user_id = 12345\n",
    "page = 1\n",
    "\n",
    "def load_user_data(user_id, page, s):\n",
    "    url = 'http://www.kinopoisk.ru/user/%d/votes/list/ord/date/page/%d/#list' % (user_id, page)\n",
    "    # %d - это первый парметр урла. а следующийй %d - это второй. После % в скобках идут сами парметры\n",
    "    request = session.get(url)\n",
    "    return request.text #на выходе мы получаем текст страницы\n",
    "\n",
    "def contain_movies_data(text):\n",
    "    soup = BeautifulSoup(text) #передаем текст в суп\n",
    "    film_list = soup.find('div', {'class': 'profileFilmsList'}) #ищет тег с оценкой\n",
    "    return film_list is not None # интересный ход, делает ретурн только если есть что-то? Есл ретурна нет, то закончится перебор в цикле while\n",
    "\n",
    "#Отсюда стартуем запуск. Ктсати она (автор) при парсинге страниц использует не for цикл, а while\n",
    "#она не знает сколько страниц, поэтому будет перебирать пока есть страница с оценками.\n",
    "#т.е пока будет находится тег {'class': 'profileFilmsList'}\n",
    "\n",
    "while True:\n",
    "    data = load_user_data(user_id, page, s)#запускаем первую функцию и передаем ее вывод в дата\n",
    "    if contain_movies_data(data): #вот это как раз и есть условие для перебора.Пока будет ретурн от второй функции\n",
    "        with open('./page_%d.html' % (page), 'w') as output_file:\n",
    "            #сохраняем в домашнюю (./) папку файл с именем page_номер страницы на запись\n",
    "            output_file.write(data.encode('cp1251'))\n",
    "            page += 1\n",
    "    else:\n",
    "            break# завершить цикл, если стрниц больше нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Часть 2 - Парсинг страниц'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Автор не указала точку входа'''\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename) as input_file:\n",
    "        text = input_file.read()\n",
    "    return text\n",
    "\n",
    "def parse_user_datafile_bs(filename):\n",
    "    results = []\n",
    "    text = read_file(filename)\n",
    "\n",
    "    soup = BeautifulSoup(text)\n",
    "    film_list = soup.find('div', {'class': 'profileFilmsList'}) #находим первый тего\n",
    "    items = film_list.find_all('div', {'class': ['item', 'item even']}) # в нем находим все теги item even\n",
    "    for item in items:\n",
    "        # getting movie_id\n",
    "#         movie_link = item.find('div', {'class': 'nameRus'}).find('a').get('href') #ссылка на фильм\n",
    "        movie_desc = item.find('div', {'class': 'nameRus'}).find('a').text  #название фильма\n",
    "        movie_id = re.findall('\\d+', movie_link)[0] #.re - это вроде как модуль регекспов.Здесь команда найти все /d+ и первый элмент. Без страницы не понять.\n",
    "\n",
    "        # getting english name\n",
    "        name_eng = item.find('div', {'class': 'nameEng'}).text\n",
    "\n",
    "        #getting watch time\n",
    "        watch_datetime = item.find('div', {'class': 'date'}).text\n",
    "        date_watched, time_watched = re.match('(\\d{2}\\.\\d{2}\\.\\d{4}), (\\d{2}:\\d{2})', watch_datetime).groups() #что за метод .groups?\n",
    "\n",
    "        # getting user rating\n",
    "        user_rating = item.find('div', {'class': 'vote'}).text\n",
    "        if user_rating:\n",
    "            user_rating = int(user_rating)\n",
    "\n",
    "        results.append({\n",
    "                'movie_id': movie_id,\n",
    "                'name_eng': name_eng,\n",
    "                'date_watched': date_watched,\n",
    "                'time_watched': time_watched,\n",
    "                'user_rating': user_rating,\n",
    "                'movie_desc': movie_desc\n",
    "            }) # сложила все в словарик\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ЧТо узнал нового.\n",
    "Надо глянуть на метод .re и .groups()\n",
    "Это ссылка на саму статью, мало ли https://habr.com/ru/post/280238/\n",
    "В самой статье есть примечания. что делать, если на сайте аутентификация (как ее пройти из питон-кода),\n",
    "а также , как обрабатывать разные контролсы. И ссылка на курс Udacity\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
